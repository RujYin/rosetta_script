# Merge the energy score generated by Rosetta and confidence score given by protenix

import os
import re
import json
import csv

# ==== Configurable paths ====
output_path = "./T311/output"  # Directory with confidence JSON files
output_file = "./rosetta_scripts/output/combined_results.csv"  # Final CSV
energy_scores_file = "./rosetta_scripts/output/scores.sc"  # Rosetta score.sc file
clustering_file = "./rosetta_scripts/cluster_0.95.txt"  # Clustering file

# ==== Step 1: Parse clustering ====
cluster_dict = {}
valid_names = set()

with open(clustering_file) as f:
    for line in f:
        if "Cluster" in line and "->" in line:
            match = re.match(r"Cluster\s+(\d+)\s*->\s*(.+)", line.strip())
            if match:
                cluster_id = match.group(1)
                paths = match.group(2).split()
                for path in paths:
                    name = os.path.basename(path).replace("_0001", "")
                    cluster_dict[name] = cluster_id
                    valid_names.add(name)

# ==== Step 2: Parse energy scores ====
score_dict = {}
score_values = []

with open(energy_scores_file) as f:
    for line in f:
        if line.startswith("SCORE:") and "total_score" not in line:
            parts = line.strip().split()
            score = float(parts[1])
            full_name = parts[-1].replace("_0001", "")
            if full_name in valid_names:
                score_dict[full_name] = score
                score_values.append(score)

# Rank total scores (ascending = better)
sorted_scores = sorted(set(score_values))
score_ranks = {v: i + 1 for i, v in enumerate(sorted_scores)}

# ==== Step 3: Parse confidence scores only for clustered names ====
conf_dict = {}
conf_values = []

for root, _, files in os.walk(output_path):
    for file in files:
        if file.endswith(".json") and "summary_confidence" in file:
            name = file.replace("_summary_confidence_", "_").replace(".json", "")
            if name not in valid_names:
                continue

            try:
                with open(os.path.join(root, file)) as f:
                    data = json.load(f)
                v1 = data["chain_pair_iptm"][2][0]
                v2 = data["chain_pair_iptm"][2][1]
                avg = (v1 + v2) / 2
                conf_dict[name] = avg
                conf_values.append(avg)
            except Exception as e:
                print(f"Failed to process {file}: {e}")

# Rank confidence scores (descending = better)
sorted_conf = sorted(set(conf_values), reverse=True)
conf_ranks = {v: i + 1 for i, v in enumerate(sorted_conf)}

# ==== Step 4: Merge and write ====
all_names = valid_names  # We only use clustered names

rows = []
for name in all_names:
    score = score_dict.get(name)
    conf = conf_dict.get(name)
    cluster_id = cluster_dict[name]
    score_rank = score_ranks[score]
    conf_rank = conf_ranks[conf]
    rows.append((name, score, score_rank, conf, conf_rank, cluster_id))

# Sort by energy score rank (ascending)
rows.sort(key=lambda x: x[2])

# Write to output CSV
with open(output_file, "w", newline='') as out:
    writer = csv.writer(out)
    writer.writerow(["name", "total_score", "score_rank", "conf_score", "conf_score_rank", "cluster_id"])
    writer.writerows(rows)

print(f"Saved combined results to: {output_file}")
